+++
title = "The universality of intelligence"
draft = true
date = 2025-11-09
description = ""
tags = [ "thoughts"]

+++

# Context
Recommended reading: the recent New Yorker piece, [The Case that A.I. is Thinking](https://www.newyorker.com/magazine/2025/11/10/the-case-that-ai-is-thinking).

Here are some thoughts I had after reading it broken down by category:

## Agreement
Overall, I think the author hits upon much of what I've been thinking about over the past few years (with my own additions):

#### Three camps
In my experience, when talking about AI, and specifically about it's forward trajectory and probability of further significant progress, people fall into three camps:
1. The unaware. They've heard about it on the news, sure, but they don't have a strong opinion themselves about what is going to happen or how they feel about it.
1. Those in denial. They either don't want it to happen (due to it's impact on artists, copyright law, the environment, jobs, etc) or still believe that it won't happen or _can't_ happen because we still don't have the right ingredients/trajectory, or is fundamentally impossible.
1. The believers. These people have seen enough (often software engineers as is the case for the author James Somers) and by standing near enough the "event horizon", seeing the progress and having practice at wielding and building tools, it's clear that something is there, it's just a matter of if, not when.

I resonated very strongly with his statement, "How convincing does the illusion of understanding have to be before you stop calling it an illusion?"

For those who don't find that convincing, I'd recommend you take a quiet moment and think about all the evidence you have that the humans around you are actually sentient beings. Gemini tells me that this is called Solipsism in philosophy, and that some of the arguments against it are,

> Many philosophers, particularly Ludwig Wittgenstein, argued that the very existence of language and shared knowledge defeats solipsism.
>
> * The Private Language Argument: Wittgenstein contended that a purely private language—one whose words refer only to sensations that only I can know—is impossible. For a word to have meaning, it must be possible to establish and follow a rule for its use. Rules require the possibility of being checked or verified by an external standard or by others.
>
> * Intersubjectivity: Our concepts of truth, morality, and even physical objects are inherently intersubjective (shared between minds). If only my mind existed, there would be no distinction between being right and merely seeming right. The reality of shared communication suggests the reality of shared minds.

Which is funny, because these sound like pretty strong arguments that LLMs, masters of language, are likely to converge on a similar trajectory for thought that we all share.

## Surprise
The author describes some recent conversations with Douglas Hofstadter,

> When we spoke, however, he sounded profoundly disappointed—and frightened. Current A.I. research “confirms a lot of my ideas, but it also takes away from the beauty of what humanity is,” he told me. “When I was younger, much younger, I wanted to know what underlay creativity, the mechanisms of creativity. That was a holy grail for me. But now I want it to remain a mystery.”

I was somewhat disappointed to read this (as a great admirer of Hofstadter's works and thought process) because I personally find it extremely exciting that we are making progress in uncovering the nature of intelligence and will quote Feynman here for an explanation for how deeply understanding something can provide _more_ appreciation, rather than less. From [this source](https://fs.blog/richard-feynman-on-beauty/), but the quote appears to come from the book [_The Pleasure of Finding Things Out_](https://www.jamesvermillion.com/notebook/the-beauty-of-a-flower-and-five-lessons-from-richardnbspfeynman)

> I have a friend who’s an artist and has sometimes taken a view which I don’t agree with very well. He’ll hold up a flower and say “look how beautiful it is,” and I’ll agree. Then he says “I as an artist can see how beautiful this is but you as a scientist take this all apart and it becomes a dull thing,” and I think that he’s kind of nutty. First of all, the beauty that he sees is available to other people and to me too, I believe. Although I may not be quite as refined aesthetically as he is … I can appreciate the beauty of a flower. At the same time, I see much more about the flower than he sees. I could imagine the cells in there, the complicated actions inside, which also have a beauty. I mean it’s not just beauty at this dimension, at one centimeter; there’s also beauty at smaller dimensions, the inner structure, also the processes. The fact that the colors in the flower evolved in order to attract insects to pollinate it is interesting; it means that insects can see the color. It adds a question: does this aesthetic sense also exist in the lower forms? Why is it aesthetic? All kinds of interesting questions which the science knowledge only adds to the excitement, the mystery and the awe of a flower. It only adds. I don’t understand how it subtracts.


https://www.anthropic.com/research/introspection
